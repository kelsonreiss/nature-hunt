{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant links\n",
    "\n",
    "Model itself is based on this Kaggle Kernel: https://www.kaggle.com/hsinwenchang/keras-mobilenet-data-augmentation-visualize\n",
    "\n",
    "iNaturalist data 2017 download: https://github.com/visipedia/inat_comp/blob/master/2017/README.md\n",
    "\n",
    "iNaturalist data 2018 download: https://github.com/visipedia/inat_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, Conv2D,MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNet\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....................................................x.........................s.........................................x....................................s...s......ss.......................................................................................................ssssss...................................................................x....x.........................x......x.................................................ssss.....s............\n",
      "----------------------------------------------------------------------\n",
      "Ran 457 tests in 1.507s\n",
      "\n",
      "OK (skipped=16, expected failures=6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=457 errors=0 failures=0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# tests recommended by: http://docs.h5py.org/en/stable/build.html\n",
    "# package needed to convert Keras model -> TensorFlow Lite\n",
    "h5py.run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kelson/Kaggle'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in unscrambled category data\n",
    "\n",
    "# (TODO: Adjust this path based on where downloaded data + info is)\n",
    "path_to_categories_json = '../Downloads/categories.json'\n",
    "with open(path_to_categories_json) as data_file_categories:\n",
    "    categories = json.load(data_file_categories)\n",
    "    \n",
    "# Read in Kingdom and category ID info\n",
    "# categories_df = pd.DataFrame(categories)[['kingdom', 'id', 'name', 'genus']].rename(columns={'id':'category_id'})\n",
    "categories_df = pd.DataFrame(categories).rename(columns={'id':'category_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>category_id</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>name</th>\n",
       "      <th>order</th>\n",
       "      <th>phylum</th>\n",
       "      <th>supercategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polychaeta</td>\n",
       "      <td>Amphinomidae</td>\n",
       "      <td>Hermodice</td>\n",
       "      <td>0</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Hermodice carunculata</td>\n",
       "      <td>Phyllodocida</td>\n",
       "      <td>Annelida</td>\n",
       "      <td>Animalia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polychaeta</td>\n",
       "      <td>Sabellariidae</td>\n",
       "      <td>Phragmatopoma</td>\n",
       "      <td>1</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Phragmatopoma californica</td>\n",
       "      <td>Sabellida</td>\n",
       "      <td>Annelida</td>\n",
       "      <td>Animalia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polychaeta</td>\n",
       "      <td>Sabellidae</td>\n",
       "      <td>Eudistylia</td>\n",
       "      <td>2</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Eudistylia vancouveri</td>\n",
       "      <td>Sabellida</td>\n",
       "      <td>Annelida</td>\n",
       "      <td>Animalia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polychaeta</td>\n",
       "      <td>Serpulidae</td>\n",
       "      <td>Galeolaria</td>\n",
       "      <td>3</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Galeolaria hystrix</td>\n",
       "      <td>Sabellida</td>\n",
       "      <td>Annelida</td>\n",
       "      <td>Animalia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polychaeta</td>\n",
       "      <td>Serpulidae</td>\n",
       "      <td>Serpula</td>\n",
       "      <td>4</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Serpula columbiana</td>\n",
       "      <td>Sabellida</td>\n",
       "      <td>Annelida</td>\n",
       "      <td>Animalia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class         family          genus  category_id   kingdom  \\\n",
       "0  Polychaeta   Amphinomidae      Hermodice            0  Animalia   \n",
       "1  Polychaeta  Sabellariidae  Phragmatopoma            1  Animalia   \n",
       "2  Polychaeta     Sabellidae     Eudistylia            2  Animalia   \n",
       "3  Polychaeta     Serpulidae     Galeolaria            3  Animalia   \n",
       "4  Polychaeta     Serpulidae        Serpula            4  Animalia   \n",
       "\n",
       "                        name         order    phylum supercategory  \n",
       "0      Hermodice carunculata  Phyllodocida  Annelida      Animalia  \n",
       "1  Phragmatopoma californica     Sabellida  Annelida      Animalia  \n",
       "2      Eudistylia vancouveri     Sabellida  Annelida      Animalia  \n",
       "3         Galeolaria hystrix     Sabellida  Annelida      Animalia  \n",
       "4         Serpula columbiana     Sabellida  Annelida      Animalia  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_trim(path):\n",
    "    # Load Data from JSON\n",
    "    with open(path) as data_file:\n",
    "        anns = json.load(data_file)\n",
    "    # Read in Image + Category Pairs\n",
    "    anns_df = pd.DataFrame(anns['annotations'])[['image_id', 'category_id']]\n",
    "    \n",
    "    # Read in Image + File_Name Pairs\n",
    "    img_df = pd.DataFrame(anns['images'])[['id', 'file_name']].rename(columns={'id':'image_id'})\n",
    "\n",
    "    # Merge \n",
    "    df_file_cat = pd.merge(img_df, anns_df, on='image_id')\n",
    "    \n",
    "    # Add category name to file\n",
    "    df_file_w_kingdom = pd.merge(df_file_cat, categories_df, on='category_id')\n",
    "    \n",
    "    # converting to string to use sparse_categorical_crossentropy\n",
    "    df_file_w_kingdom['category_id'] = df_file_w_kingdom['category_id'].astype(str)\n",
    "    \n",
    "    # Retain only the records with the category as Plantae or Fungi\n",
    "    df_file_w_kingdom = df_file_w_kingdom[df_file_w_kingdom['kingdom'].isin(['Plantae', 'Fungi'])]\n",
    "\n",
    "    return df_file_w_kingdom\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>class</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>name</th>\n",
       "      <th>order</th>\n",
       "      <th>phylum</th>\n",
       "      <th>supercategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>train_val2018/Plantae/7477/3b60c9486db1d2ee875...</td>\n",
       "      <td>7477</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Platanaceae</td>\n",
       "      <td>Platanus</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Platanus occidentalis</td>\n",
       "      <td>Proteales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4336</td>\n",
       "      <td>train_val2018/Plantae/7477/3d5d7f1e0eedb1df3aa...</td>\n",
       "      <td>7477</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Platanaceae</td>\n",
       "      <td>Platanus</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Platanus occidentalis</td>\n",
       "      <td>Proteales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4736</td>\n",
       "      <td>train_val2018/Plantae/7477/c0843babf2fe1b24b6c...</td>\n",
       "      <td>7477</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Platanaceae</td>\n",
       "      <td>Platanus</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Platanus occidentalis</td>\n",
       "      <td>Proteales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10022</td>\n",
       "      <td>train_val2018/Plantae/7477/1645a80d3bb42125d3f...</td>\n",
       "      <td>7477</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Platanaceae</td>\n",
       "      <td>Platanus</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Platanus occidentalis</td>\n",
       "      <td>Proteales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10296</td>\n",
       "      <td>train_val2018/Plantae/7477/5b96d95868a7e97b97e...</td>\n",
       "      <td>7477</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Platanaceae</td>\n",
       "      <td>Platanus</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Platanus occidentalis</td>\n",
       "      <td>Proteales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                          file_name category_id  \\\n",
       "0         1  train_val2018/Plantae/7477/3b60c9486db1d2ee875...        7477   \n",
       "1      4336  train_val2018/Plantae/7477/3d5d7f1e0eedb1df3aa...        7477   \n",
       "2      4736  train_val2018/Plantae/7477/c0843babf2fe1b24b6c...        7477   \n",
       "3     10022  train_val2018/Plantae/7477/1645a80d3bb42125d3f...        7477   \n",
       "4     10296  train_val2018/Plantae/7477/5b96d95868a7e97b97e...        7477   \n",
       "\n",
       "           class       family     genus  kingdom                   name  \\\n",
       "0  Magnoliopsida  Platanaceae  Platanus  Plantae  Platanus occidentalis   \n",
       "1  Magnoliopsida  Platanaceae  Platanus  Plantae  Platanus occidentalis   \n",
       "2  Magnoliopsida  Platanaceae  Platanus  Plantae  Platanus occidentalis   \n",
       "3  Magnoliopsida  Platanaceae  Platanus  Plantae  Platanus occidentalis   \n",
       "4  Magnoliopsida  Platanaceae  Platanus  Plantae  Platanus occidentalis   \n",
       "\n",
       "       order         phylum supercategory  \n",
       "0  Proteales  Magnoliophyta       Plantae  \n",
       "1  Proteales  Magnoliophyta       Plantae  \n",
       "2  Proteales  Magnoliophyta       Plantae  \n",
       "3  Proteales  Magnoliophyta       Plantae  \n",
       "4  Proteales  Magnoliophyta       Plantae  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_train_data = '../Downloads/train2018.json'\n",
    "path_to_val_data = '../Downloads/val2018.json'\n",
    "\n",
    "# Retrieve and parse data\n",
    "train_df = retrieve_and_trim(path_to_train_data)\n",
    "val_df = retrieve_and_trim(path_to_val_data)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_df['kingdom'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125664\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/hsinwenchang/keras-mobilenet-data-augmentation-visualize\n",
    "numTrainingImages = len(train_df['image_id'])\n",
    "numValidImages = len(val_df['image_id'])\n",
    "print(numTrainingImages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>class</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>name</th>\n",
       "      <th>order</th>\n",
       "      <th>phylum</th>\n",
       "      <th>supercategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>437514</td>\n",
       "      <td>train_val2018/Plantae/7291/9f8ecb39e5f767e39e9...</td>\n",
       "      <td>7291</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Euphorbiaceae</td>\n",
       "      <td>Euphorbia</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Euphorbia ophthalmica</td>\n",
       "      <td>Malpighiales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>445585</td>\n",
       "      <td>train_val2018/Plantae/7291/a283eed3c7fcfd2b2f8...</td>\n",
       "      <td>7291</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Euphorbiaceae</td>\n",
       "      <td>Euphorbia</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Euphorbia ophthalmica</td>\n",
       "      <td>Malpighiales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>460454</td>\n",
       "      <td>train_val2018/Plantae/7291/05bc377ee8066c43ac1...</td>\n",
       "      <td>7291</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Euphorbiaceae</td>\n",
       "      <td>Euphorbia</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Euphorbia ophthalmica</td>\n",
       "      <td>Malpighiales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>437516</td>\n",
       "      <td>train_val2018/Plantae/7228/cfb9ca114758b134ae2...</td>\n",
       "      <td>7228</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Verbenaceae</td>\n",
       "      <td>Glandularia</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Glandularia pumila</td>\n",
       "      <td>Lamiales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>438162</td>\n",
       "      <td>train_val2018/Plantae/7228/7f8fe3242e3bbe6e357...</td>\n",
       "      <td>7228</td>\n",
       "      <td>Magnoliopsida</td>\n",
       "      <td>Verbenaceae</td>\n",
       "      <td>Glandularia</td>\n",
       "      <td>Plantae</td>\n",
       "      <td>Glandularia pumila</td>\n",
       "      <td>Lamiales</td>\n",
       "      <td>Magnoliophyta</td>\n",
       "      <td>Plantae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                          file_name category_id  \\\n",
       "0    437514  train_val2018/Plantae/7291/9f8ecb39e5f767e39e9...        7291   \n",
       "1    445585  train_val2018/Plantae/7291/a283eed3c7fcfd2b2f8...        7291   \n",
       "2    460454  train_val2018/Plantae/7291/05bc377ee8066c43ac1...        7291   \n",
       "6    437516  train_val2018/Plantae/7228/cfb9ca114758b134ae2...        7228   \n",
       "7    438162  train_val2018/Plantae/7228/7f8fe3242e3bbe6e357...        7228   \n",
       "\n",
       "           class         family        genus  kingdom                   name  \\\n",
       "0  Magnoliopsida  Euphorbiaceae    Euphorbia  Plantae  Euphorbia ophthalmica   \n",
       "1  Magnoliopsida  Euphorbiaceae    Euphorbia  Plantae  Euphorbia ophthalmica   \n",
       "2  Magnoliopsida  Euphorbiaceae    Euphorbia  Plantae  Euphorbia ophthalmica   \n",
       "6  Magnoliopsida    Verbenaceae  Glandularia  Plantae     Glandularia pumila   \n",
       "7  Magnoliopsida    Verbenaceae  Glandularia  Plantae     Glandularia pumila   \n",
       "\n",
       "          order         phylum supercategory  \n",
       "0  Malpighiales  Magnoliophyta       Plantae  \n",
       "1  Malpighiales  Magnoliophyta       Plantae  \n",
       "2  Malpighiales  Magnoliophyta       Plantae  \n",
       "6      Lamiales  Magnoliophyta       Plantae  \n",
       "7      Lamiales  Magnoliophyta       Plantae  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT IF NEED TO GENERATE ANOTHER COPY OF SPECIES LIST\n",
    "\n",
    "# Generate csv file containing info about all species \n",
    "# all_species_df = train_df.copy(deep=True)\n",
    "# all_species_df = all_species_df.drop(columns=['image_id', 'file_name'])\n",
    "\n",
    "# Remove duplicates\n",
    "# keep = 'first' means the first entry of a set in duplicates remains in the DF\n",
    "# all_species_df= all_species_df.drop_duplicates(keep='first')\n",
    "\n",
    "# https://datatofish.com/export-dataframe-to-csv/\n",
    "\n",
    "# all_species_df.to_csv('../nature-hunt/deep_learning_model_work/2018_species_list.csv')\n",
    "\n",
    "# all_species_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrieve_and_trim_17(path):\n",
    "#     # Load Data from JSON\n",
    "#     with open(path) as data_file:\n",
    "#         anns = json.load(data_file)\n",
    "#     # Read in Image + Category Pairs\n",
    "#     anns_df = pd.DataFrame(anns['annotations'])[['image_id', 'category_id']]\n",
    "    \n",
    "#     # Read in Image + File_Name Pairs\n",
    "#     img_df = pd.DataFrame(anns['images'])[['id', 'file_name']].rename(columns={'id':'image_id'})\n",
    "\n",
    "#     # Merge \n",
    "#     df_file_cat_id_only = pd.merge(img_df, anns_df, on='image_id')\n",
    "    \n",
    "#     # Read in categories\n",
    "#     df_file_cat_data = pd.DataFrame(anns['categories']).rename(columns={'id':'category_id'})\n",
    "    \n",
    "#     # Merge category data \n",
    "#     df_file_all = pd.merge(df_file_cat_data, df_file_cat_id_only, on='category_id')\n",
    "    \n",
    "#     # Retain only the records with the category as Plantae or Fungi\n",
    "#     #df_file_w_kingdom = df_file_w_kingdom[df_file_w_kingdom['kingdom'].isin(['Plantae', 'Fungi'])]\n",
    "\n",
    "#     return df_file_all[df_file_all['supercategory'].isin(['Plantae', 'Fungi'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in 2017 data\n",
    "\n",
    "# path_to_train_data_17 = '../Downloads/train_val2017/train2017.json'\n",
    "# path_to_val_data_17 = '../Downloads/train_val2017/val2017.json'\n",
    "\n",
    "# # Retrieve and parse data\n",
    "# train_df_17 = retrieve_and_trim_17(path_to_train_data_17)\n",
    "# val_df_17 = retrieve_and_trim_17(path_to_val_data_17)\n",
    "\n",
    "# train_df_17.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(val_df_17['category_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gauge overlap between 2017 & 2018 data\n",
    "# # 2017 = 2222 plant and fungi species total\n",
    "# names_2017 = val_df_17['name'].drop_duplicates(keep='first').to_frame()\n",
    "\n",
    "# # 2018 = 3238 plant and fungi species\n",
    "# names_2018 = val_df['name'].drop_duplicates(keep='first').to_frame()\n",
    "\n",
    "# merged_names = pd.merge(names_2017, names_2018, on='name')\n",
    "# len(merged_names.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decided not to use any of the 2017 data\n",
    "\n",
    "1. 2017 data doesn't include other informational data - genus, class, etc. I expect to use genus classification\n",
    "as a \"valid find\" too for the scavenger hunt app, so that is important to have on hand.\n",
    "\n",
    "2. There were 807 overlapping species between 2017 and 2018. I didn't want to include the 2017 \n",
    "supplementary images to train on, as that would lead to a data imbalance - the species found in both 2017 and 2018\n",
    "would have more data. Suggested to be problematic here: https://datascience.stackexchange.com/questions/38796/unbalanced-training-data-for-different-classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE NB_EPOCHS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238\n"
     ]
    }
   ],
   "source": [
    "# Number of classes \n",
    "nb_classes = len(train_df['category_id'].unique())\n",
    "print(nb_classes)\n",
    "\n",
    "# Batch Size \n",
    "# https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network\n",
    "# Tradeoff for batch size: larger batch size trains faster but uses more memory and may be less accurate\n",
    "\n",
    "batch_size = 128\n",
    "img_size = 128\n",
    "\n",
    "# Going to run a one epoch model training to estimate how long each takes\n",
    "\n",
    "nb_epochs = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider using ModelCheckpoint or EarlyStopping\n",
    "\n",
    "https://keras.io/callbacks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Questions to answer:\n",
    "1. Number of Epochs?\n",
    "2. Steps per epoch?\n",
    "3. Validation steps?\n",
    "4. Accuracy / Val Accuracy vs Loss / Val Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the cell below, use ImageDataGenerator to create a transformation that rescales the images by 255 \n",
    "\n",
    "here I applied Data Augmentation as following:\n",
    "random 45 degree rotation\n",
    "random zoom of up to 50%\n",
    "random horizontal flip\n",
    "width shift of 0.15\n",
    "height shfit of 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE DIRECTORY PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "CPU times: user 786 ms, sys: 137 ms, total: 923 ms\n",
      "Wall time: 930 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelson/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 125664 invalid image filename(s) in x_col=\"file_name\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training Data\n",
    "train_datagenerator = ImageDataGenerator(rescale=1./255, rotation_range=45, \n",
    "                                         width_shift_range=.15,\n",
    "                                        height_shift_range=.15,\n",
    "                                        horizontal_flip=True,\n",
    "                                        zoom_range=0.5)\n",
    "\n",
    "train_generator = train_datagenerator.flow_from_dataframe(dataframe=train_df,\n",
    "                                                          directory=\"../input/train_val2018\",\n",
    "                                                          x_col=\"file_name\",\n",
    "                                                          y_col=\"category_id\",\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          shuffle=True, #shuffles order of batches at beginning of each epoch\n",
    "                                                          # use sparse not categorical because labels are integers not one-hot encoded : https://datascience.stackexchange.com/questions/39132/keras-dimension-error-with-sparse-categorical-crossentropy\n",
    "                                                          class_mode=\"sparse\", #https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy\n",
    "                                                          target_size = (img_size, img_size))\n",
    "                                                                                                          \n",
    "                                                          \n",
    "                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE DIRECTORY PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "CPU times: user 77.5 ms, sys: 14.1 ms, total: 91.7 ms\n",
      "Wall time: 89.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelson/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 9714 invalid image filename(s) in x_col=\"file_name\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Validation Data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_generator=test_datagen.flow_from_dataframe(dataframe=val_df,\n",
    "                                                directory=\"../input/train_val2018\",\n",
    "                                                 x_col=\"file_name\",\n",
    "                                                 y_xol=\"category_id\",\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode=\"sparse\",\n",
    "                                                 target_size=(img_size , img_size))\n",
    "                                                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet Model\n",
    "\n",
    "Initializes weights randomly, so does full training. An alternative Kaggle kernel uses ImageNet weights, freezes the model, adds a few on top and just trains those - example of FineTuning / Transfer Learning. \n",
    "\n",
    "I want to have more customization for better (hopefully) performance\n",
    "Kernel here: https://www.kaggle.com/ateplyuk/inat2019-starter-keras-efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 129, 129, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 3238)        3318950   \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3238)              0         \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 3238)              0         \n",
      "=================================================================\n",
      "Total params: 6,547,814\n",
      "Trainable params: 6,525,926\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = MobileNet(input_shape=(img_size, img_size,3), \n",
    "                  alpha=1., # alpha is \"Width Multiplier\"\n",
    "                 weights=None, # use None along with custom classes parameter for random initialization of weights\n",
    "                 classes=nb_classes)\n",
    "\n",
    "\n",
    "# Link on overview of optimizers: http://ruder.io/optimizing-gradient-descent/index.html#rmsprop\n",
    "# Seems like Adam and rmsprop are relatively similar \n",
    "# will use RMSprop because that's what is used in both Kaggle Kernels with high performance on similar data\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use callbacks to save the best model\n",
    "# Further parameter explanations: https://keras.io/callbacks/\n",
    "\n",
    "model_save_name = \"MobileNet_1.h5\"\n",
    "checkpoint = ModelCheckpoint(model_save_name, # save destination\n",
    "                             monitor='val_loss', # loss on validation data\n",
    "                            verbose=1, #verbosity\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=False, # save whole model\n",
    "                            mode='auto',\n",
    "                            period=1) # Interval (number of epochs) between checkpoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "input and filter must have the same depth: 3 vs 32\n\t [[{{node conv_dw_1_1/depthwise}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: input and filter must have the same depth: 3 vs 32\n\t [[{{node conv_dw_1_1/depthwise}}]]"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Specify number of steps = size of training data / batch size\n",
    "trainingEpochSteps = numTrainingImages / batch_size\n",
    "valEpochSteps = numValidImages / batch_size\n",
    "\n",
    "history = model.fit_generator(generator = train_generator,\n",
    "                             steps_per_epoch = trainingEpochSteps,  \n",
    "                             validation_data = valid_generator,\n",
    "                             validation_steps = valEpochSteps, \n",
    "                             epochs = nb_epochs,\n",
    "                             verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow Lite\n",
    "# https://www.tensorflow.org/lite/convert/python_api\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(model_save_name)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
